{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marcins\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:925: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0113 21:01:14.782461  6500 filelock.py:274] Lock 2700347751952 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\e512a74b9a525c868c0560254b3a65dc6309948f8cb99a8375429de673d28332.60289bb41d6aec457a093f9438a2c590beb41d64e7c830eac00dc56d3d49c5f6.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4985c92736e455691a1c3b110d5557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=664.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:01:15.285712  6500 filelock.py:318] Lock 2700347751952 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\e512a74b9a525c868c0560254b3a65dc6309948f8cb99a8375429de673d28332.60289bb41d6aec457a093f9438a2c590beb41d64e7c830eac00dc56d3d49c5f6.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:01:15.779169  6500 filelock.py:274] Lock 2700744085968 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\ca58839b8e4b1222703e13158ffeb3a5a7330260cbc39513f74710674d70268b.ad71128a5739887a02bfa6de2fa8768f86e02cd13d0c308873f4cdba254e4c7c.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e582946abfec4d16b9fcc9c645fbf7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1629877663.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:04:53.901858  6500 filelock.py:318] Lock 2700744085968 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\ca58839b8e4b1222703e13158ffeb3a5a7330260cbc39513f74710674d70268b.ad71128a5739887a02bfa6de2fa8768f86e02cd13d0c308873f4cdba254e4c7c.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-large-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0113 21:05:06.034097  6500 filelock.py:274] Lock 2700865528328 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\896a66aee72d4d4a712ae44174ac53b9b8773dc3f8bf3fd42ffa6e8a3bfc0942.adf299ef80f3ee4dff5abe4e65a8ff8b436992d5df16b7ed0a192de08e0b142d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473926f472e64da68c176bbcc4311248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=906984.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:08.113498  6500 filelock.py:318] Lock 2700865528328 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\896a66aee72d4d4a712ae44174ac53b9b8773dc3f8bf3fd42ffa6e8a3bfc0942.adf299ef80f3ee4dff5abe4e65a8ff8b436992d5df16b7ed0a192de08e0b142d.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:08.597543  6500 filelock.py:274] Lock 2700865571752 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\b807cc87c1bba7cbc8e619224f5a9c1d12c51a5d74ec95b6113a42016f1e4a71.b43456cc5f4fc752a150d7e61b1fe9eec2c958f067aa08884125223b8872d968.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b02e568e61a475aabad8f4eaa77a4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=555571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:10.166152  6500 filelock.py:318] Lock 2700865571752 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\b807cc87c1bba7cbc8e619224f5a9c1d12c51a5d74ec95b6113a42016f1e4a71.b43456cc5f4fc752a150d7e61b1fe9eec2c958f067aa08884125223b8872d968.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:11.120369  6500 filelock.py:274] Lock 2700865571920 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\7e8fe8852a1ff7e03195cb41fac16af837f8c14a34a61850b02a7395eb294f00.b8e113717eb1828d09e47de853cf49c8fad05ebdce24df2614cd942dc23e2a77.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f6a67729904d5ea325e47eab9b35f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:11.606164  6500 filelock.py:318] Lock 2700865571920 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\7e8fe8852a1ff7e03195cb41fac16af837f8c14a34a61850b02a7395eb294f00.b8e113717eb1828d09e47de853cf49c8fad05ebdce24df2614cd942dc23e2a77.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:12.090501  6500 filelock.py:274] Lock 2700865569680 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\c3fa56a2b1773fb2675060a9c0820375b11ce1bd22a308b5abc5ffe340ef45f2.5399d59cc1c4147c064f53c77a985e2d758532b64d5d5a3adc8653637876150d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147ec543465b418c8d8b66cc44fa199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=229.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:12.603809  6500 filelock.py:318] Lock 2700865569680 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\c3fa56a2b1773fb2675060a9c0820375b11ce1bd22a308b5abc5ffe340ef45f2.5399d59cc1c4147c064f53c77a985e2d758532b64d5d5a3adc8653637876150d.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:13.824635  6500 filelock.py:274] Lock 2701533565616 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\47f8ea4fa59e5c085091266b56ce31865dabae82040a49fd00853b9c87f4260b.b1306d5e8846e5a8cd2dd9617a32d94defcccc67c63606517d44e6683a99a9bc.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2aab3aa7f4a46178cf578a02acef19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=459.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:14.326497  6500 filelock.py:318] Lock 2701533565616 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\47f8ea4fa59e5c085091266b56ce31865dabae82040a49fd00853b9c87f4260b.b1306d5e8846e5a8cd2dd9617a32d94defcccc67c63606517d44e6683a99a9bc.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:05:14.807345  6500 filelock.py:274] Lock 2700865925472 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\cc0ac32ccc0366c085b3ffe6af9029366be6ad0a90a404181e66f748cab0ac3f.99290c7e218fedd697967412d617ee4c63a508566adb3aabaa6954305c9f8673.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5123647f7225420bb28c3c5eb8668877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=531146786.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:25.674616  6500 filelock.py:318] Lock 2700865925472 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\cc0ac32ccc0366c085b3ffe6af9029366be6ad0a90a404181e66f748cab0ac3f.99290c7e218fedd697967412d617ee4c63a508566adb3aabaa6954305c9f8673.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0113 21:06:30.649899  6500 filelock.py:274] Lock 2700865929112 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\5cc92c71750d69fbba4cd553d98048fec5217cb2fd4482afbe430bf11a3ef0d9.bcbf7cb1e2902f50128b9e3a2d6391295d56ab12612fb2eca5a26be0e641e4ca.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8d1654eeaf465495f51e938d4fc3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=489360.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:32.128696  6500 filelock.py:318] Lock 2700865929112 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\5cc92c71750d69fbba4cd553d98048fec5217cb2fd4482afbe430bf11a3ef0d9.bcbf7cb1e2902f50128b9e3a2d6391295d56ab12612fb2eca5a26be0e641e4ca.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:33.052002  6500 filelock.py:274] Lock 2700355671544 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\5469275f8724d7024853da799dad550a062c8316ac750e10920737fbfa813e20.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6d55eb59e44c25a958c31f6867a4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:33.557077  6500 filelock.py:318] Lock 2700355671544 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\5469275f8724d7024853da799dad550a062c8316ac750e10920737fbfa813e20.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:34.016624  6500 filelock.py:274] Lock 2700744086472 acquired on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\eb313d5be906eaeb2fb01492172034245931c494f37f89a24bfcbee677a96360.6ddf388f5788b6e5b2caea105d16b508f5073d6848f73068cc71d218d32b2e1a.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62198dfbe2e84ccd9e3a0bce07b7023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 21:06:34.510327  6500 filelock.py:318] Lock 2700744086472 released on C:\\Users\\MarcinS/.cache\\huggingface\\transformers\\eb313d5be906eaeb2fb01492172034245931c494f37f89a24bfcbee677a96360.6ddf388f5788b6e5b2caea105d16b508f5073d6848f73068cc71d218d32b2e1a.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {}\n",
    "\n",
    "model_name__ =  'allegro/herbert-base-cased'\n",
    "model__ = AutoModelWithLMHead.from_pretrained(model_name__)\n",
    "tokenizer__ = AutoTokenizer.from_pretrained(model_name__)\n",
    "models[model_name__] = {'m':model__,'t':tokenizer__}\n",
    "\n",
    "model_name__ = \"allegro/herbert-large-cased\"\n",
    "model__ = AutoModelWithLMHead.from_pretrained(model_name__)\n",
    "tokenizer__ = AutoTokenizer.from_pretrained(model_name__)\n",
    "models[model_name__] = {'m':model__,'t':tokenizer__}\n",
    "\n",
    "model_name__ = \"dkleczek/bert-base-polish-cased-v1\"\n",
    "model__ = BertForMaskedLM.from_pretrained(model_name__)\n",
    "tokenizer__ = BertTokenizer.from_pretrained(model_name__)\n",
    "models[model_name__] = {'m':model__,'t':tokenizer__}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spaces(n):\n",
    "    return ''.join([' 'for i in range(n)])\n",
    "\n",
    "def space_wrapper(word,n=20):\n",
    "#     assert (n>=len(word))\n",
    "    return word + spaces(n-len(word))\n",
    "\n",
    "def c_n_times(c,n):\n",
    "    return ''.join([c for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def top_predictions(sentences, top_n, models,mask = '[MASK]'):\n",
    "    short_model_name ={}\n",
    "    short_names = ['A','B','C']\n",
    "    for letter, model_name in zip(short_names,models.keys()):\n",
    "        print(f'model {letter} = {model_name}')\n",
    "        short_model_name[model_name]=letter\n",
    "    print('')\n",
    "    for org_sentence in sentences: \n",
    "        model_top = {}\n",
    "        for model_name, model_and_tokenizer in models.items():\n",
    "            model = model_and_tokenizer['m']\n",
    "            tokenizer = model_and_tokenizer['t']\n",
    "            sentence = f'{org_sentence}'\n",
    "            if mask in sentence:\n",
    "                sentence = sentence.replace(mask, tokenizer.mask_token)\n",
    "            else:\n",
    "                sentence = sentence +' '+ tokenizer.mask_token + '.'\n",
    "\n",
    "            tokenized = tokenizer.encode(sentence, return_tensors='pt')\n",
    "            mask_token_index = torch.where(tokenized == tokenizer.mask_token_id)[1]\n",
    "\n",
    "            token_logits = model(tokenized, return_dict=True).logits\n",
    "            mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "            top_tokens = torch.topk(mask_token_logits, top_n, dim=1).indices[0].tolist()\n",
    "            model_top[model_name] = [ tokenizer.decode([top_tokens[i]]) for i in range(len(top_tokens))]\n",
    "        print(sentence)\n",
    "        print(f'| |',end='')\n",
    "        for model_name in models:\n",
    "            print(f'{space_wrapper(short_model_name[model_name])}|',end='')\n",
    "        print('')\n",
    "        for i in range(top_n):\n",
    "            print(f'|{i}|',end='')\n",
    "            for model_name in models:\n",
    "                print(f'{space_wrapper(model_top[model_name][i])}|',end='')\n",
    "            print('')\n",
    "            c= '-'\n",
    "            print(f'{c_n_times(c,3+3*21)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model A = allegro/herbert-base-cased\n",
      "model B = allegro/herbert-large-cased\n",
      "model C = dkleczek/bert-base-polish-cased-v1\n",
      "\n",
      "Warszawa to największe  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|miasto              |miasto              |miasto              |\n",
      "------------------------------------------------------------------\n",
      "|1|lotnisko            |miasta              |województwo         |\n",
      "------------------------------------------------------------------\n",
      "|2|centrum             |.                   |lotnisko            |\n",
      "------------------------------------------------------------------\n",
      "|3|miasta              |lotnisko            |miasteczko          |\n",
      "------------------------------------------------------------------\n",
      "|4|atrakcje            |miast               |państwo             |\n",
      "------------------------------------------------------------------\n",
      "Te zabawki należą do  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|rodziny             |dzieci              |ciebie              |\n",
      "------------------------------------------------------------------\n",
      "|1|nas                 |mnie                |mnie                |\n",
      "------------------------------------------------------------------\n",
      "|2|nich                |nas                 |nas                 |\n",
      "------------------------------------------------------------------\n",
      "|3|najlepszych         |najmłodszych        |pana                |\n",
      "------------------------------------------------------------------\n",
      "|4|.                   |Ciebie              |niego               |\n",
      "------------------------------------------------------------------\n",
      "Policjant przygląda się  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|mężczyźnie          |sprawie             |temu                |\n",
      "------------------------------------------------------------------\n",
      "|1|kobiecie            |sytuacji            |sprawie             |\n",
      "------------------------------------------------------------------\n",
      "|2|mu                  |zdarzeniu           |im                  |\n",
      "------------------------------------------------------------------\n",
      "|3|dziewczynie         |wszystkiemu         |wszystkiemu         |\n",
      "------------------------------------------------------------------\n",
      "|4|sprawie             |kobiecie            |panu                |\n",
      "------------------------------------------------------------------\n",
      "Na środku skrzyżowania widać  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|rondo               |rondo               |rzekę               |\n",
      "------------------------------------------------------------------\n",
      "|1|samochody           |krzyż               |ulicę               |\n",
      "------------------------------------------------------------------\n",
      "|2|radiowóz            |radiowóz            |drzewa              |\n",
      "------------------------------------------------------------------\n",
      "|3|samochód            |samochód            |drogę               |\n",
      "------------------------------------------------------------------\n",
      "|4|wiadukt             |znak                |las                 |\n",
      "------------------------------------------------------------------\n",
      "Właściciel samochodu widział złodzieja z  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|samochodu           |bronią              |bronią              |\n",
      "------------------------------------------------------------------\n",
      "|1|włamaniem           |bliska              |tyłu                |\n",
      "------------------------------------------------------------------\n",
      "|2|auta                |kamerą              |ulicy               |\n",
      "------------------------------------------------------------------\n",
      "|3|kierowcą            |nożem               |bliska              |\n",
      "------------------------------------------------------------------\n",
      "|4|parkingu            |kamery              |zewnątrz            |\n",
      "------------------------------------------------------------------\n",
      "Prezydent z premierem rozmawiali wczoraj o  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|przyszłości         |tym                 |tym                 |\n",
      "------------------------------------------------------------------\n",
      "|1|Polsce              |sprawie             |Polsce              |\n",
      "------------------------------------------------------------------\n",
      "|2|bezpieczeństwie     |sytuacji            |budżecie            |\n",
      "------------------------------------------------------------------\n",
      "|3|polityce            |prywatyzacji        |ASF                 |\n",
      "------------------------------------------------------------------\n",
      "|4|Warszawie           |.                   |ustawie             |\n",
      "------------------------------------------------------------------\n",
      "Witaj drogi  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|Łukasz              |człowieku           |chłopcze            |\n",
      "------------------------------------------------------------------\n",
      "|1|Boże                |Panie               |przyjacielu         |\n",
      "------------------------------------------------------------------\n",
      "|2|człowieku           |Jezu                |bracie              |\n",
      "------------------------------------------------------------------\n",
      "|3|Karol               |panie               |kolego              |\n",
      "------------------------------------------------------------------\n",
      "|4|Marcin              |misiu               |synu                |\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#zad 3 \n",
    "sentences = ['Warszawa to największe ',\n",
    "             'Te zabawki należą do ',\n",
    "             'Policjant przygląda się ',\n",
    "             'Na środku skrzyżowania widać ',\n",
    "             'Właściciel samochodu widział złodzieja z ', \n",
    "             'Prezydent z premierem rozmawiali wczoraj o ',\n",
    "             'Witaj drogi ']\n",
    "\n",
    "top_predictions(sentences, 5,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model A = allegro/herbert-base-cased\n",
      "model B = allegro/herbert-large-cased\n",
      "model C = dkleczek/bert-base-polish-cased-v1\n",
      "\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie  [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|zdziwił             |bał                 |zgodził             |\n",
      "------------------------------------------------------------------\n",
      "|1|poddał              |poddał              |dowiedział          |\n",
      "------------------------------------------------------------------\n",
      "|2|dowiedział          |zabił               |martwił             |\n",
      "------------------------------------------------------------------\n",
      "|3|zastanawiał         |śmiał               |bał                 |\n",
      "------------------------------------------------------------------\n",
      "|4|przyznał            |zastanawiał         |zabił               |\n",
      "------------------------------------------------------------------\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie   [MASK].\n",
      "| |A                   |B                   |C                   |\n",
      "|0|dowiedziała         |bała                |zgodziła            |\n",
      "------------------------------------------------------------------\n",
      "|1|przyznała           |zgodziła            |bała                |\n",
      "------------------------------------------------------------------\n",
      "|2|bała                |dowiedziała         |dowiedziała         |\n",
      "------------------------------------------------------------------\n",
      "|3|śmiała              |zmieniła            |zabiła              |\n",
      "------------------------------------------------------------------\n",
      "|4|zmieniła            |śmiała              |pojawiła            |\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#zad 4\n",
    "sentences = ['Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ',\n",
    "             'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie  ']\n",
    "top_predictions(sentences, 5, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model A = allegro/herbert-base-cased\n",
      "model B = allegro/herbert-large-cased\n",
      "model C = dkleczek/bert-base-polish-cased-v1\n",
      "\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "| |A                   |B                   |C                   |\n",
      "|0|Woda                |Woda                |Woda                |\n",
      "------------------------------------------------------------------\n",
      "|1|Słońce              |Krew                |Mięso               |\n",
      "------------------------------------------------------------------\n",
      "|2|Ziemia              |woda                |Słońce              |\n",
      "------------------------------------------------------------------\n",
      "|3|Następnie           |Ogień               |Nie                 |\n",
      "------------------------------------------------------------------\n",
      "|4|Ciało               |Nie                 |Piwo                |\n",
      "------------------------------------------------------------------\n",
      "W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\n",
      "| |A                   |B                   |C                   |\n",
      "|0|Kraków              |Oslo                |kraj                |\n",
      "------------------------------------------------------------------\n",
      "|1|Oslo                |Londyn              |Cypr                |\n",
      "------------------------------------------------------------------\n",
      "|2|Londyn              |Liverpool           |Meksyk              |\n",
      "------------------------------------------------------------------\n",
      "|3|Gdańsk              |Glasgow             |Gibraltar           |\n",
      "------------------------------------------------------------------\n",
      "|4|Toruń               |Birmingham          |Wellington          |\n",
      "------------------------------------------------------------------\n",
      "Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\n",
      "| |A                   |B                   |C                   |\n",
      "|0|pewno               |AGH                 |wsi                 |\n",
      "------------------------------------------------------------------\n",
      "|1|AGH                 |UW                  |świecie             |\n",
      "------------------------------------------------------------------\n",
      "|2|UW                  |UJ                  |żywo                |\n",
      "------------------------------------------------------------------\n",
      "|3|studiach            |UAM                 |pewno               |\n",
      "------------------------------------------------------------------\n",
      "|4|UMK                 |uczelni             |odległość           |\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#zad 5\n",
    "sentences = ['[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.',\n",
    "             'W wakacje odwiedziłem [MASK], który jest stolicą Islandii.',\n",
    "             'Informatyka na [MASK] należy do najlepszych kierunków w Polsce.']\n",
    "\n",
    "top_predictions(sentences, 5, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of the models produced the best results?\n",
    "It's hard to say. model 'dkleczek/bert-base-polish-cased-v1' seems to fit best with polish grammar. Also doesn't return random full stops, when there is a clear need for word (maybe to fullfill grammatical requirement). On the other hand the same model doesn't know polish universities, where the other 2 models yielded better results. Since first 2 models are simply variations, they are returning similar results, while bert is different and not very good with context or names, but very good at keep correct grammar. \n",
    "    \n",
    "### Was any of the models able to capture Polish grammar?\n",
    "Definitely bert was the best, but made a single mistake in '\\[MASK\\] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.' returning 'Nie'. All used corect male/female endings in ex4.\n",
    "    \n",
    "### Was any of the models able to capture long-distant relationships between the words?\n",
    "allegro/herbert models were able to capture names in relation to words (universities and Oslo). Also in sentences with politicians or policeman we can see results slight, but not fully, moved toward fitting topic. So to some extended they can corelate 'prezydent' z with something political, and even with Poland. \n",
    "    \n",
    "### Was any of the models able to capture world knowledge?\n",
    "Actually quite well as we can se with water boiling temperature. Also they correlated correct universities with computer science, with the exception of last model. Or at least they didn't reaturn universty without computer science, but that maybe due to them being less known? (however like SGH is very well known so that's a hint that our models did correlate correctly).\n",
    "\n",
    "### What are the most striking errors made by the models?\n",
    "Dots when there was clearly word needed.\n",
    "\n",
    "'Informatyka na [MASK] należy do najlepszych kierunków w Polsce.' reponses of model 'bert'.\n",
    "\n",
    "'W wakacje odwiedziłem [MASK], który jest stolicą Islandii.' also 'bert' responed with 'kraj' which doesn't fit at all.\n",
    "\n",
    "I do not count water boiling temperature question answers as errors, as all models answered 'woda' and really there isn't any other word to fit there, so models had to return random words. \n",
    "\n",
    "But that's actaully all errors, the rest seems to be context dependent and/or inacurract rather than error. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
