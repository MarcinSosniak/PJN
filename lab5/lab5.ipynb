{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import requests\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "onlyfiles = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f))]\n",
    "url = 'http://localhost:9200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zad1\n",
    "def get_tagged_words(text_in):\n",
    "    text= requests.post(url, data = text_in.encode('utf-8'), headers={'Content-type': 'text/plain; charset=utf-8'}).text\n",
    "    lines = [l for l in text.split('\\n') if l != '']\n",
    "    lines_s= [line.split('\\t') for line in lines]\n",
    "    words = []\n",
    "    for i in range(1,len(lines_s),2):\n",
    "        words.append(lines_s[i][1] + ':'+lines_s[i][2].split(':')[0])\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 10/1180\n",
      "done 20/1180\n",
      "done 30/1180\n",
      "done 40/1180\n",
      "done 50/1180\n",
      "done 60/1180\n",
      "done 70/1180\n",
      "done 80/1180\n",
      "done 90/1180\n",
      "done 100/1180\n",
      "done 110/1180\n",
      "done 120/1180\n",
      "done 130/1180\n",
      "done 140/1180\n",
      "done 150/1180\n",
      "done 160/1180\n",
      "done 170/1180\n",
      "done 180/1180\n",
      "done 190/1180\n",
      "done 200/1180\n",
      "done 210/1180\n",
      "done 220/1180\n",
      "done 230/1180\n",
      "done 240/1180\n",
      "done 250/1180\n",
      "done 260/1180\n",
      "done 270/1180\n",
      "done 280/1180\n",
      "done 290/1180\n",
      "done 300/1180\n",
      "done 310/1180\n",
      "done 320/1180\n",
      "done 330/1180\n",
      "done 340/1180\n",
      "done 350/1180\n",
      "done 360/1180\n",
      "done 370/1180\n",
      "done 380/1180\n",
      "done 390/1180\n",
      "done 400/1180\n",
      "done 410/1180\n",
      "done 420/1180\n",
      "done 430/1180\n",
      "done 440/1180\n",
      "done 450/1180\n",
      "done 460/1180\n",
      "done 470/1180\n",
      "done 480/1180\n",
      "done 490/1180\n",
      "done 500/1180\n",
      "done 510/1180\n",
      "done 520/1180\n",
      "done 530/1180\n",
      "done 540/1180\n",
      "done 550/1180\n",
      "done 560/1180\n",
      "done 570/1180\n",
      "done 580/1180\n",
      "done 590/1180\n",
      "done 600/1180\n",
      "done 610/1180\n",
      "done 620/1180\n",
      "done 630/1180\n",
      "done 640/1180\n",
      "done 650/1180\n",
      "done 660/1180\n",
      "done 670/1180\n",
      "done 680/1180\n",
      "done 690/1180\n",
      "done 700/1180\n",
      "done 710/1180\n",
      "done 720/1180\n",
      "done 730/1180\n",
      "done 740/1180\n",
      "done 750/1180\n",
      "done 760/1180\n",
      "done 770/1180\n",
      "done 780/1180\n",
      "done 790/1180\n",
      "done 800/1180\n",
      "done 810/1180\n",
      "done 820/1180\n",
      "done 830/1180\n",
      "done 840/1180\n",
      "done 850/1180\n",
      "done 860/1180\n",
      "done 870/1180\n",
      "done 880/1180\n",
      "done 890/1180\n",
      "done 900/1180\n",
      "done 910/1180\n",
      "done 920/1180\n",
      "done 930/1180\n",
      "done 940/1180\n",
      "done 950/1180\n",
      "done 960/1180\n",
      "done 970/1180\n",
      "done 980/1180\n",
      "done 990/1180\n",
      "done 1000/1180\n",
      "done 1010/1180\n",
      "done 1020/1180\n",
      "done 1030/1180\n",
      "done 1040/1180\n",
      "done 1050/1180\n",
      "done 1060/1180\n",
      "done 1070/1180\n",
      "done 1080/1180\n",
      "done 1090/1180\n",
      "done 1100/1180\n",
      "done 1110/1180\n",
      "done 1120/1180\n",
      "done 1130/1180\n",
      "done 1140/1180\n",
      "done 1150/1180\n",
      "done 1160/1180\n",
      "done 1170/1180\n",
      "done 1180/1180\n"
     ]
    }
   ],
   "source": [
    "#zad 2,3\n",
    "bigrams = {}\n",
    "iter_count = 0\n",
    "for filename in onlyfiles:\n",
    "    file_content = None\n",
    "    with open(DATA_PATH+'/'+filename,'r',encoding='utf-8') as f:\n",
    "        file_content=f.read().lower()\n",
    "    words =  get_tagged_words(file_content)\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams[(words[i],words[i+1])] = bigrams.get((words[i],words[i+1]),0) +1\n",
    "    iter_count+=1\n",
    "    if iter_count % 10 ==0:\n",
    "        print('done {}/{}'.format(iter_count,len(onlyfiles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bigrams_dump' ,'wb') as bd:\n",
    "    pickle.dump(bigrams, bd )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zad4\n",
    "characters = 'aąbcćdeęfghijklłmnńoópqrsśtuvwxyzżź'\n",
    "bigrams_count_tmp = {}\n",
    "bigrams_total_value = 0\n",
    "for key,value in bigrams.items():\n",
    "    add_to_final = True\n",
    "    for word in key:\n",
    "        word = word.split(':')[0]\n",
    "        if word =='':\n",
    "            add_to_final = False\n",
    "            break\n",
    "        for c in word:\n",
    "            if not c in characters:\n",
    "                add_to_final = False\n",
    "                break\n",
    "    if add_to_final:\n",
    "        bigrams_count_tmp[key] = value\n",
    "        bigrams_total_value += value\n",
    "bigrams_count_tmp\n",
    "bigrams= bigrams_count_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tree_w1 ={}\n",
    "bigram_tree_w2 ={}\n",
    "for bigram,count in bigrams.items():\n",
    "    w1,w2 = bigram\n",
    "    try:\n",
    "        bigram_tree_w1[w1][w2] = count\n",
    "    except KeyError:\n",
    "        bigram_tree_w1[w1] = {w2:count}\n",
    "    try:\n",
    "        bigram_tree_w2[w2][w1] = count\n",
    "    except KeyError:\n",
    "        bigram_tree_w2[w2] = {w1:count}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('który:adj', 'mowa:subst'), 28644, 248954.706021335),\n",
       " (('o:prep', 'który:adj'), 28762, 190926.10508849766),\n",
       " (('mowa:subst', 'w:prep'), 28579, 177709.21936375732),\n",
       " (('w:prep', 'artykuł:brev'), 32184, 114509.06783965782),\n",
       " (('otrzymywać:fin', 'brzmienie:subst'), 10586, 111219.30919630887),\n",
       " (('w:prep', 'ustęp:brev'), 23564, 88523.27518211817),\n",
       " (('minister:subst', 'właściwy:adj'), 7949, 70982.21191642844),\n",
       " (('dodawać:fin', 'się:qub'), 8236, 66915.78701422714),\n",
       " (('i:conj', 'numer:brev'), 8464, 54505.19718120039),\n",
       " (('droga:subst', 'rozporządzenie:subst'), 4754, 54049.0773158387)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad 6b\n",
    "def H(vals,N):\n",
    "    out = 0\n",
    "    for val in vals:\n",
    "        try:\n",
    "            val_n = val/N\n",
    "            if not val_n ==0:\n",
    "                out+=val_n*log(val_n)\n",
    "        except ValueError as e:\n",
    "            print('val : '+str(val))\n",
    "            print('val_n : '+str(val_n))\n",
    "            print(vals)\n",
    "            print('log(val_n) : '+str(log(val_n)))\n",
    "            raise e\n",
    "    return out\n",
    "\n",
    "def LLR_bigram(bigram,bigrams_words_total_occurences):\n",
    "    w1,w2 = bigram\n",
    "    k11 =bigram_tree_w1[w1][w2]\n",
    "    k12 = sum(bigram_tree_w2[w2].values()) - k11\n",
    "    k21 = sum(bigram_tree_w1[w1].values()) - k11\n",
    "    k22 = bigrams_words_total_occurences -k11 -k12 - k21\n",
    "    N =  k11+ k12+ k21+ k22\n",
    "    return 2 * N * (H([k11,k12,k21,k22],N) - H([k11+k12,k21+k22],N) - H([k11+k21,k12+k22],N))\n",
    "    \n",
    "# N=sum(bigram_freq_list_words.values())\n",
    "\n",
    "llr_bigrams = list(map(lambda x: (x[0],x[1],LLR_bigram(x[0],bigrams_total_value)),bigrams.items()))\n",
    "llr_bigrams.sort(key= lambda x: -x[2])\n",
    "llr_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prep', 'subst'), 326059),\n",
       " (('subst', 'subst'), 287358),\n",
       " (('subst', 'adj'), 274246),\n",
       " (('adj', 'subst'), 187820),\n",
       " (('subst', 'prep'), 172754),\n",
       " (('subst', 'conj'), 84699),\n",
       " (('conj', 'subst'), 84220),\n",
       " (('prep', 'adj'), 79458),\n",
       " (('ger', 'subst'), 77472),\n",
       " (('prep', 'brev'), 67230)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad 7,8\n",
    "partitions = {}\n",
    "for bigram,occurences in bigrams.items():\n",
    "    tag0 = bigram[0].split(':')[1]\n",
    "    tag1 = bigram[1].split(':')[1]\n",
    "    partitions[(tag0,tag1)] = partitions.get((tag0,tag1),0) + occurences\n",
    "top_10_partitions =sorted(partitions.items(), key = lambda x: -x[1])[:10]\n",
    "top_10_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('prep', 'subst'): [(('z:prep', 'dzień:subst'), 11416, 53967.24754989901),\n",
       "  (('na:prep', 'podstawa:subst'), 6727, 47367.51104881132),\n",
       "  (('do:prep', 'sprawa:subst'), 8734, 46304.54941836767),\n",
       "  (('w:prep', 'droga:subst'), 7138, 32092.17473576187),\n",
       "  (('od:prep', 'dzień:subst'), 5359, 31861.06759087903)],\n",
       " ('subst',\n",
       "  'subst'): [(('droga:subst', 'rozporządzenie:subst'),\n",
       "   4754,\n",
       "   54049.0773158387), (('skarb:subst', 'państwo:subst'),\n",
       "   1821,\n",
       "   21925.49406434114), (('rada:subst', 'minister:subst'),\n",
       "   2265,\n",
       "   18309.769926366385), (('terytorium:subst', 'rzeczpospolita:subst'),\n",
       "   1229,\n",
       "   14317.429793192), (('ochrona:subst', 'środowisko:subst'),\n",
       "   1572,\n",
       "   14028.677468123677)],\n",
       " ('subst',\n",
       "  'adj'): [(('minister:subst', 'właściwy:adj'),\n",
       "   7949,\n",
       "   70982.21191642844), (('rzeczpospolita:subst',\n",
       "    'polski:adj'), 3636, 43656.726644248054), (('jednostka:subst',\n",
       "    'organizacyjny:adj'),\n",
       "   2260,\n",
       "   24600.692689416686), (('samorząd:subst', 'terytorialny:adj'),\n",
       "   1675,\n",
       "   23385.261073351612), (('produkt:subst', 'leczniczy:adj'),\n",
       "   1738,\n",
       "   21905.430353677548)],\n",
       " ('adj', 'subst'): [(('który:adj', 'mowa:subst'), 28644, 248954.706021335),\n",
       "  (('niniejszy:adj', 'ustawa:subst'), 2373, 21496.787253969007),\n",
       "  (('następujący:adj', 'zmiana:subst'), 1624, 18153.925571933483),\n",
       "  (('odrębny:adj', 'przepis:subst'), 1461, 13051.086380244307),\n",
       "  (('walny:adj', 'zgromadzenie:subst'), 598, 9652.216123283408)],\n",
       " ('subst', 'prep'): [(('mowa:subst', 'w:prep'), 28579, 177709.21936375732),\n",
       "  (('ustawa:subst', 'z:prep'), 8676, 42089.75115134961),\n",
       "  (('wniosek:subst', 'o:prep'), 2768, 16431.135843524164),\n",
       "  (('dzień:subst', 'od:prep'), 2517, 13920.381180227689),\n",
       "  (('miesiąc:subst', 'od:prep'), 1590, 12370.503870025745)],\n",
       " ('subst', 'conj'): [(('przecinek:subst', 'i:conj'), 647, 3958.3943558751907),\n",
       "  (('imię:subst', 'i:conj'), 495, 2303.0018012465457),\n",
       "  (('wolność:subst', 'albo:conj'), 323, 2267.1848925238237),\n",
       "  (('całość:subst', 'lub:conj'), 381, 2190.4446794540013),\n",
       "  (('zasada:subst', 'i:conj'), 870, 1908.998720563361)],\n",
       " ('conj', 'subst'): [(('i:conj', 'tryb:subst'), 1264, 4696.137135118556),\n",
       "  (('i:conj', 'nazwisko:subst'), 477, 2615.3158372818525),\n",
       "  (('i:conj', 'usługa:subst'), 643, 1877.944087738331),\n",
       "  (('i:conj', 'adres:subst'), 387, 1752.5538393683637),\n",
       "  (('i:conj', 'wychowanie:subst'), 272, 1460.1954661123443)],\n",
       " ('prep', 'adj'): [(('o:prep', 'który:adj'), 28762, 190926.10508849766),\n",
       "  (('za:prep', 'każdy:adj'), 267, 1362.9789969154588),\n",
       "  (('w:prep', 'ten:adj'), 2800, 1311.9177449443455),\n",
       "  (('w:prep', 'właściwy:adj'), 104, 1285.659498502759),\n",
       "  (('przez:prep', 'ten:adj'), 658, 1029.1369370493446)],\n",
       " ('ger',\n",
       "  'subst'): [(('zasięgnąć:ger', 'opinia:subst'),\n",
       "   787,\n",
       "   11522.355764032944), (('pozbawić:ger',\n",
       "    'wolność:subst'), 797, 11281.445258765749), (('wykonywać:ger',\n",
       "    'zawód:subst'),\n",
       "   561,\n",
       "   5569.8986831620405), (('zawrzeć:ger', 'umowa:subst'),\n",
       "   508,\n",
       "   5265.0366103361785), (('wszcząć:ger', 'postępowanie:subst'),\n",
       "   503,\n",
       "   5124.071230103087)],\n",
       " ('prep', 'brev'): [(('w:prep', 'artykuł:brev'), 32184, 114509.06783965782),\n",
       "  (('w:prep', 'ustęp:brev'), 23564, 88523.27518211817),\n",
       "  (('w:prep', 'punkt:brev'), 3766, 10989.334755363745),\n",
       "  (('z:prep', 'późniejszy:brev'), 1032, 7663.750551649794),\n",
       "  (('w:prep', 'dziennik:brev'), 965, 4725.172714731656)]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zad9\n",
    "top_10_partitions_dicts = { k: [] for k  in list(map(lambda x: x[0],top_10_partitions))}\n",
    "top_10_partitions_dicts\n",
    "for bigram,occurance,score in llr_bigrams:\n",
    "    tag0 = bigram[0].split(':')[1]\n",
    "    tag1 = bigram[1].split(':')[1]\n",
    "    for parition in top_10_partitions_dicts.keys():\n",
    "        if len(top_10_partitions_dicts[parition]) >= 5:\n",
    "            continue\n",
    "        if not(tag0 == parition[0] and  tag1  == parition[1]):\n",
    "            continue\n",
    "        top_10_partitions_dicts[parition].append((bigram,occurance,score))\n",
    "\n",
    "top_10_partitions_dicts         \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#zad 10\n",
    "\n",
    "1) What types of bigrams have been found?\n",
    "\n",
    "('prep', 'subst') ('subst', 'subst')('subst', 'adj')('adj', 'subst')('subst', 'prep')('subst', 'conj')('conj', 'subst')('prep', 'adj')('ger', 'subst')('prep', 'brev'). Just as without tagging, LLR found very commonly occuring bigrams. Even more so than in labs4, cause here we also cut down paritions, to most popular ones, further eliminating important, but not so common (and thus not most obvious),\n",
    "bigrams. \n",
    "\n",
    "2)Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "\n",
    "here is a lot of nouns in valuable multiword expression (since nouns and adjective tend to bring meaning rather than grammar, and are thus are imporatant). However less usefull, while really popular, are combos of preps with something or abbrevations with something like 'w pkt.' 'w ust.' 'o którym/która etc.'\n",
    "\n",
    "3) Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "\n",
    "Since we sorted by LLR score it's hard to say, but it seems like syntactic category would a very good filtration tool. For example it's quite obvious after reading one document that 'w ust.' will be very common, so i don't think a special analisys is necessary to figure that information about given data, and can be easily filtered out in order to look for less obious pairs.\n",
    "\n",
    "4) Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem\n",
    "\n",
    "\n",
    "We could probably to try it to create better translators. Some words would imply diffrenet meanings. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
